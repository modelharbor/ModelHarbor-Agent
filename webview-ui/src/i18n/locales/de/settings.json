{
	"common": {
		"save": "Guardar",
		"done": "Hecho",
		"cancel": "Cancelar",
		"reset": "Restablecer",
		"select": "Seleccionar",
		"add": "Añadir encabezado",
		"remove": "Eliminar"
	},
	"header": {
		"title": "Configuración",
		"saveButtonTooltip": "Guardar cambios",
		"nothingChangedTooltip": "Nada ha cambiado",
		"doneButtonTooltip": "Descartar cambios no guardados y cerrar el panel de configuración"
	},
	"unsavedChangesDialog": {
		"title": "Cambios no guardados",
		"description": "¿Desea descartar los cambios y continuar?",
		"cancelButton": "Cancelar",
		"discardButton": "Descartar cambios"
	},
	"sections": {
		"providers": "Proveedores",
		"autoApprove": "Auto-aprobación",
		"browser": "Acceso al ordenador",
		"checkpoints": "Puntos de control",
		"notifications": "Notificaciones",
		"contextManagement": "Contexto",
		"terminal": "Terminal",
		"prompts": "Indicaciones",
		"experimental": "Experimental",
		"language": "Idioma",
		"about": "Acerca de ModelHarbor Agent"
	},
	"prompts": {
		"description": "Configura indicaciones de soporte que se utilizan para acciones rápidas como mejorar indicaciones, explicar código y solucionar problemas. Estas indicaciones ayudan a ModelHarbor a brindar mejor asistencia para tareas comunes de desarrollo."
	},
	"codeIndex": {
		"title": "Indexación de código",
		"enableLabel": "Habilitar indexación de código",
		"enableDescription": "<0>La indexación de código</0> es una función experimental que crea un índice de búsqueda semántica de tu proyecto usando embeddings de IA. Esto permite a ModelHarbor Agent entender mejor y navegar grandes bases de código encontrando código relevante basado en significado en lugar de solo palabras clave.",
		"providerLabel": "Proveedor de embeddings",
		"selectProviderPlaceholder": "Seleccionar proveedor",
		"openaiProvider": "OpenAI",
		"ollamaProvider": "Ollama",
		"openaiCompatibleProvider": "Compatible con OpenAI",
		"openaiCompatibleBaseUrlLabel": "URL base:",
		"openaiCompatibleApiKeyLabel": "Clave API:",
		"openaiCompatibleModelDimensionLabel": "Dimensión de Embedding:",
		"openaiCompatibleModelDimensionPlaceholder": "ej., 1536",
		"openaiCompatibleModelDimensionDescription": "La dimensión de embedding (tamaño de salida) para tu modelo. Consulta la documentación de tu proveedor para este valor. Valores comunes: 384, 768, 1536, 3072.",
		"openaiKeyLabel": "Clave de OpenAI:",
		"modelLabel": "Modelo",
		"selectModelPlaceholder": "Seleccionar modelo",
		"ollamaUrlLabel": "URL de Ollama:",
		"qdrantUrlLabel": "URL de Qdrant",
		"qdrantKeyLabel": "Clave de Qdrant:",
		"advancedConfigLabel": "Configuración avanzada",
		"searchMinScoreLabel": "Umbral de puntuación de búsqueda",
		"searchMinScoreDescription": "Puntuación mínima de similitud (0.0-1.0) requerida para los resultados de búsqueda. Valores más bajos devuelven más resultados pero pueden ser menos relevantes. Valores más altos devuelven menos resultados pero más relevantes.",
		"searchMinScoreResetTooltip": "Restablecer al valor predeterminado (0.4)",
		"startIndexingButton": "Iniciar indexación",
		"clearIndexDataButton": "Borrar datos de índice",
		"unsavedSettingsMessage": "Por favor guarda tus ajustes antes de iniciar el proceso de indexación.",
		"clearDataDialog": {
			"title": "¿Estás seguro?",
			"description": "Esta acción no se puede deshacer. Esto eliminará permanentemente los datos de índice de tu base de código.",
			"cancelButton": "Cancelar",
			"confirmButton": "Borrar datos"
		}
	},
	"autoApprove": {
		"description": "Permitir que ModelHarbor realice operaciones automáticamente sin requerir aprobación. Habilite esta configuración solo si confía plenamente en la IA y comprende los riesgos de seguridad asociados.",
		"readOnly": {
			"label": "Lectura",
			"description": "Cuando está habilitado, ModelHarbor verá automáticamente el contenido del directorio y leerá archivos sin que necesite hacer clic en el botón Aprobar.",
			"outsideWorkspace": {
				"label": "Incluir archivos fuera del espacio de trabajo",
				"description": "Permitir a ModelHarbor leer archivos fuera del espacio de trabajo actual sin requerir aprobación."
			}
		},
		"write": {
			"label": "Escritura",
			"description": "Crear y editar archivos automáticamente sin requerir aprobación",
			"delayLabel": "Retraso después de escritura para permitir que los diagnósticos detecten posibles problemas",
			"outsideWorkspace": {
				"label": "Incluir archivos fuera del espacio de trabajo",
				"description": "Permitir a ModelHarbor crear y editar archivos fuera del espacio de trabajo actual sin requerir aprobación."
			},
			"protected": {
				"label": "Incluir archivos protegidos",
				"description": "Permitir a ModelHarbor crear y editar archivos protegidos (como .rooignore y archivos de configuración .roo/) sin requerir aprobación."
			}
		},
		"browser": {
			"label": "Navegador",
			"description": "Realizar acciones del navegador automáticamente sin requerir aprobación. Nota: Solo se aplica cuando el modelo admite el uso del ordenador"
		},
		"retry": {
			"label": "Reintentar",
			"description": "Reintentar automáticamente solicitudes de API fallidas cuando el servidor devuelve una respuesta de error",
			"delayLabel": "Retraso antes de reintentar la solicitud"
		},
		"mcp": {
			"label": "MCP",
			"description": "Habilitar la aprobación automática de herramientas MCP individuales en la vista de Servidores MCP (requiere tanto esta configuración como la casilla \"Permitir siempre\" de la herramienta)"
		},
		"modeSwitch": {
			"label": "Modo",
			"description": "Cambiar automáticamente entre diferentes modos sin requerir aprobación"
		},
		"subtasks": {
			"label": "Subtareas",
			"description": "Permitir la creación y finalización de subtareas sin requerir aprobación"
		},
		"followupQuestions": {
			"label": "Pregunta",
			"description": "Seleccionar automáticamente la primera respuesta sugerida para preguntas de seguimiento después del tiempo de espera configurado",
			"timeoutLabel": "Tiempo de espera antes de seleccionar automáticamente la primera respuesta"
		},
		"execute": {
			"label": "Ejecutar",
			"description": "Ejecutar automáticamente comandos de terminal permitidos sin requerir aprobación",
			"allowedCommands": "Comandos de auto-ejecución permitidos",
			"allowedCommandsDescription": "Prefijos de comandos que pueden ser ejecutados automáticamente cuando \"Aprobar siempre operaciones de ejecución\" está habilitado. Añade * para permitir todos los comandos (usar con precaución).",
			"commandPlaceholder": "Ingrese prefijo de comando (ej. 'git ')",
			"addButton": "Añadir"
		},
		"apiRequestLimit": {
			"title": "Solicitudes máximas",
			"description": "Realizar automáticamente esta cantidad de solicitudes a la API antes de pedir aprobación para continuar con la tarea.",
			"unlimited": "Ilimitado"
		}
	},
	"providers": {
		"providerDocumentation": "{{provider}} documentation",
		"configProfile": "Configuration Profile",
		"description": "Save different API configurations to quickly switch between providers and settings.",
		"apiProvider": "API Provider",
		"model": "Model",
		"nameEmpty": "Name cannot be empty",
		"nameExists": "A profile with this name already exists",
		"deleteProfile": "Delete Profile",
		"invalidArnFormat": "Invalid ARN format. Please check the examples above.",
		"enterNewName": "Enter new name",
		"addProfile": "Add Profile",
		"renameProfile": "Rename Profile",
		"newProfile": "New Configuration Profile",
		"enterProfileName": "Enter profile name",
		"createProfile": "Create Profile",
		"cannotDeleteOnlyProfile": "Cannot delete the only profile",
		"searchPlaceholder": "Search profiles",
		"noMatchFound": "No matching profiles found",
		"vscodeLmDescription": " The VS Code Language Model API allows you to run models provided by other VS Code extensions (including but not limited to GitHub Copilot). The easiest way to get started is to install the Copilot and Copilot Chat extensions from the VS Code Marketplace.",
		"awsCustomArnUse": "Enter a valid Amazon Bedrock ARN for the model you want to use. Format examples:",
		"awsCustomArnDesc": "Make sure the region in the ARN matches your selected AWS Region above.",
		"openRouterApiKey": "OpenRouter API Key",
		"getOpenRouterApiKey": "Get OpenRouter API Key",
		"apiKeyStorageNotice": "API keys are stored securely in VSCode's Secret Storage",
		"glamaApiKey": "Glama API Key",
		"getGlamaApiKey": "Get Glama API Key",
		"useCustomBaseUrl": "Use custom base URL",
		"useReasoning": "Enable reasoning",
		"useHostHeader": "Use custom Host header",
		"useLegacyFormat": "Use legacy OpenAI API format",
		"customHeaders": "Custom Headers",
		"headerName": "Header name",
		"headerValue": "Header value",
		"noCustomHeaders": "No custom headers defined. Click the + button to add one.",
		"requestyApiKey": "Requesty API Key",
		"refreshModels": {
			"label": "Refresh Models",
			"hint": "Please reopen the settings to see the latest models.",
			"loading": "Refreshing models list...",
			"success": "Models list refreshed successfully!",
			"error": "Failed to refresh models list. Please try again."
		},
		"getRequestyApiKey": "Get Requesty API Key",
		"openRouterTransformsText": "Compress prompts and message chains to the context size (<a>OpenRouter Transforms</a>)",
		"anthropicApiKey": "Anthropic API Key",
		"getAnthropicApiKey": "Get Anthropic API Key",
		"anthropicUseAuthToken": "Pass Anthropic API Key as Authorization header instead of X-Api-Key",
		"chutesApiKey": "Chutes API Key",
		"getChutesApiKey": "Get Chutes API Key",
		"deepSeekApiKey": "DeepSeek API Key",
		"getDeepSeekApiKey": "Get DeepSeek API Key",
		"geminiApiKey": "Gemini API Key",
		"getGroqApiKey": "Get Groq API Key",
		"groqApiKey": "Groq API Key",
		"getGeminiApiKey": "Get Gemini API Key",
		"openAiApiKey": "OpenAI API Key",
		"apiKey": "API Key",
		"openAiBaseUrl": "Base URL",
		"getOpenAiApiKey": "Get OpenAI API Key",
		"mistralApiKey": "Mistral API Key",
		"getMistralApiKey": "Get Mistral / Codestral API Key",
		"codestralBaseUrl": "Codestral Base URL (Optional)",
		"codestralBaseUrlDesc": "Set an alternative URL for the Codestral model.",
		"xaiApiKey": "xAI API Key",
		"getXaiApiKey": "Get xAI API Key",
		"litellmApiKey": "LiteLLM API Key",
		"litellmBaseUrl": "LiteLLM Base URL",
		"modelharborApiKey": "ModelHarbor API Key",
		"getModelHarborApiKey": "Get ModelHarbor API Key",
		"awsCredentials": "AWS Credentials",
		"awsProfile": "AWS Profile",
		"awsProfileName": "AWS Profile Name",
		"awsAccessKey": "AWS Access Key",
		"awsSecretKey": "AWS Secret Key",
		"awsSessionToken": "AWS Session Token",
		"awsRegion": "AWS Region",
		"awsCrossRegion": "Use cross-region inference",
		"awsBedrockVpc": {
			"useCustomVpcEndpoint": "Use custom VPC endpoint",
			"vpcEndpointUrlPlaceholder": "Enter VPC Endpoint URL (optional)",
			"examples": "Examples:"
		},
		"enablePromptCaching": "Enable prompt caching",
		"enablePromptCachingTitle": "Enable prompt caching to improve performance and reduce costs for supported models.",
		"cacheUsageNote": "Note: If you don't see cache usage, try selecting a different model and then selecting your desired model again.",
		"vscodeLmModel": "Language Model",
		"vscodeLmWarning": "Note: This is a very experimental integration and provider support will vary. If you get an error about a model not being supported, that's an issue on the provider's end.",
		"googleCloudSetup": {
			"title": "To use Google Cloud Vertex AI, you need to:",
			"step1": "1. Create a Google Cloud account, enable the Vertex AI API & enable the desired Claude models.",
			"step2": "2. Install the Google Cloud CLI & configure application default credentials.",
			"step3": "3. Or create a service account with credentials."
		},
		"googleCloudCredentials": "Google Cloud Credentials",
		"googleCloudKeyFile": "Google Cloud Key File Path",
		"googleCloudProjectId": "Google Cloud Project ID",
		"googleCloudRegion": "Google Cloud Region",
		"lmStudio": {
			"baseUrl": "Base URL (optional)",
			"modelId": "Model ID",
			"speculativeDecoding": "Enable Speculative Decoding",
			"draftModelId": "Draft Model ID",
			"draftModelDesc": "Draft model must be from the same model family for speculative decoding to work correctly.",
			"selectDraftModel": "Select Draft Model",
			"noModelsFound": "No draft models found. Please ensure LM Studio is running with Server Mode enabled.",
			"description": "LM Studio allows you to run models locally on your computer. For instructions on how to get started, see their <a>quickstart guide</a>. You will also need to start LM Studio's <b>local server</b> feature to use it with this extension. <span>Note:</span> ModelHarbor Agent uses complex prompts and works best with Claude models. Less capable models may not work as expected."
		},
		"ollama": {
			"baseUrl": "Base URL (optional)",
			"modelId": "Model ID",
			"description": "Ollama allows you to run models locally on your computer. For instructions on how to get started, see their quickstart guide.",
			"warning": "Note: ModelHarbor Agent uses complex prompts and works best with Claude models. Less capable models may not work as expected."
		},
		"unboundApiKey": "Unbound API Key",
		"getUnboundApiKey": "Get Unbound API Key",
		"unboundRefreshModelsSuccess": "Models list updated! You can now select from the latest models.",
		"unboundInvalidApiKey": "Invalid API key. Please check your API key and try again.",
		"humanRelay": {
			"description": "No API key is required, but the user needs to help copy and paste the information to the web chat AI.",
			"instructions": "During use, a dialog box will pop up and the current message will be copied to the clipboard automatically. You need to paste these to web versions of AI (such as ChatGPT or Claude), then copy the AI's reply back to the dialog box and click the confirm button."
		},
		"openRouter": {
			"providerRouting": {
				"title": "OpenRouter Provider Routing",
				"description": "OpenRouter routes requests to the best available providers for your model. By default, requests are load balanced across the top providers to maximize uptime. However, you can choose a specific provider to use for this model.",
				"learnMore": "Learn more about provider routing"
			}
		},
		"customModel": {
			"capabilities": "Configure the capabilities and pricing for your custom OpenAI-compatible model. Be careful when specifying the model capabilities, as they can affect how ModelHarbor Agent performs.",
			"maxTokens": {
				"label": "Max Output Tokens",
				"description": "Maximum number of tokens the model can generate in a response. (Specify -1 to allow the server to set the max tokens.)"
			},
			"contextWindow": {
				"label": "Context Window Size",
				"description": "Total tokens (input + output) the model can process."
			},
			"imageSupport": {
				"label": "Image Support",
				"description": "Is this model capable of processing and understanding images?"
			},
			"computerUse": {
				"label": "Computer Use",
				"description": "Is this model capable of interacting with a browser? (e.g. Claude 3.7 Sonnet)."
			},
			"promptCache": {
				"label": "Prompt Caching",
				"description": "Is this model capable of caching prompts?"
			},
			"pricing": {
				"input": {
					"label": "Input Price",
					"description": "Cost per million tokens in the input/prompt. This affects the cost of sending context and instructions to the model."
				},
				"output": {
					"label": "Output Price",
					"description": "Cost per million tokens in the model's response. This affects the cost of generated content and completions."
				},
				"cacheReads": {
					"label": "Cache Reads Price",
					"description": "Cost per million tokens for reading from the cache. This is the price charged when a cached response is retrieved."
				},
				"cacheWrites": {
					"label": "Cache Writes Price",
					"description": "Cost per million tokens for writing to the cache. This is the price charged when a prompt is cached for the first time."
				}
			},
			"resetDefaults": "Reset to Defaults"
		},
		"rateLimitSeconds": {
			"label": "Rate limit",
			"description": "Minimum time between API requests."
		},
		"reasoningEffort": {
			"label": "Model Reasoning Effort",
			"high": "High",
			"medium": "Medium",
			"low": "Low"
		},
		"setReasoningLevel": "Enable Reasoning Effort",
		"claudeCode": {
			"pathLabel": "Claude Code Path",
			"description": "Optional path to your Claude Code CLI. Defaults to 'claude' if not set.",
			"placeholder": "Default: claude"
		}
	},
	"browser": {
		"enable": {
			"label": "Browser-Tool aktivieren",
			"description": "Wenn aktiviert, kann ModelHarbor einen Browser verwenden, um mit Websites zu interagieren, wenn Modelle verwendet werden, die Computer-Nutzung unterstützen. <0>Mehr erfahren</0>"
		},
		"viewport": {
			"label": "Viewport-Größe",
			"description": "Wählen Sie die Viewport-Größe für Browser-Interaktionen. Dies beeinflusst, wie Websites angezeigt und mit ihnen interagiert wird.",
			"options": {
				"largeDesktop": "Großer Desktop (1280x800)",
				"smallDesktop": "Kleiner Desktop (900x600)",
				"tablet": "Tablet (768x1024)",
				"mobile": "Mobil (360x640)"
			}
		},
		"screenshotQuality": {
			"label": "Screenshot-Qualität",
			"description": "Passen Sie die WebP-Qualität von Browser-Screenshots an. Höhere Werte bieten klarere Screenshots, erhöhen aber den Token-Verbrauch."
		},
		"remote": {
			"label": "Remote-Browser-Verbindung verwenden",
			"description": "Verbindung zu einem Chrome-Browser herstellen, der mit aktiviertem Remote-Debugging läuft (--remote-debugging-port=9222).",
			"urlPlaceholder": "Benutzerdefinierte URL (z.B. http://localhost:9222)",
			"testButton": "Verbindung testen",
			"testingButton": "Teste...",
			"instructions": "Geben Sie die DevTools-Protokoll-Host-Adresse ein oder lassen Sie das Feld leer, um Chrome lokale Instanzen automatisch zu erkennen. Die Schaltfläche 'Verbindung testen' versucht die benutzerdefinierte URL, wenn angegeben, oder erkennt automatisch, wenn das Feld leer ist."
		}
	},
	"checkpoints": {
		"enable": {
			"label": "Automatische Kontrollpunkte aktivieren",
			"description": "Wenn aktiviert, erstellt ModelHarbor automatisch Kontrollpunkte während der Aufgabenausführung, was die Überprüfung von Änderungen oder die Rückkehr zu früheren Zuständen erleichtert. <0>Mehr erfahren</0>"
		}
	},
	"notifications": {
		"sound": {
			"label": "Soundeffekte aktivieren",
			"description": "Wenn aktiviert, spielt ModelHarbor Soundeffekte für Benachrichtigungen und Ereignisse ab.",
			"volumeLabel": "Lautstärke"
		},
		"tts": {
			"label": "Text-zu-Sprache aktivieren",
			"description": "Wenn aktiviert, liest ModelHarbor seine Antworten mit Text-zu-Sprache laut vor.",
			"speedLabel": "Geschwindigkeit"
		}
	},
	"contextManagement": {
		"description": "Steuern Sie, welche Informationen im KI-Kontextfenster enthalten sind, was den Token-Verbrauch und die Antwortqualität beeinflusst",
		"autoCondenseContextPercent": {
			"label": "Schwellenwert für intelligente Kontextkomprimierung",
			"description": "Wenn das Kontextfenster diesen Schwellenwert erreicht, wird ModelHarbor es automatisch komprimieren."
		},
		"condensingApiConfiguration": {
			"label": "API-Konfiguration für Kontextkomprimierung",
			"description": "Wählen Sie, welche API-Konfiguration für Kontextkomprimierungsoperationen verwendet werden soll. Lassen Sie unausgewählt, um die aktuelle aktive Konfiguration zu verwenden.",
			"useCurrentConfig": "Aktuelle Konfiguration verwenden"
		},
		"customCondensingPrompt": {
			"label": "Benutzerdefinierter Kontextkomprimierungs-Prompt",
			"description": "Passen Sie den System-Prompt an, der für die Kontextkomprimierung verwendet wird. Lassen Sie leer, um den Standard-Prompt zu verwenden.",
			"placeholder": "Geben Sie hier Ihren benutzerdefinierten Komprimierungs-Prompt ein...\n\nSie können die gleiche Struktur wie der Standard-Prompt verwenden:\n- Vorherige Konversation\n- Aktuelle Arbeit\n- Wichtige technische Konzepte\n- Relevante Dateien und Code\n- Problemlösung\n- Ausstehende Aufgaben und nächste Schritte",
			"reset": "Auf Standard zurücksetzen",
			"hint": "Leer = Standard-Prompt verwenden"
		},
		"autoCondenseContext": {
			"name": "Intelligente Kontextkomprimierung automatisch auslösen",
			"description": "Wenn aktiviert, wird ModelHarbor automatisch den Kontext komprimieren, wenn der Schwellenwert erreicht wird. Wenn deaktiviert, können Sie die Kontextkomprimierung weiterhin manuell auslösen."
		},
		"openTabs": {
			"label": "Geöffnete Tabs Kontextlimit",
			"description": "Maximale Anzahl von VSCode-Tabs, die im Kontext enthalten sein sollen. Höhere Werte bieten mehr Kontext, erhöhen aber den Token-Verbrauch."
		},
		"workspaceFiles": {
			"label": "Workspace-Dateien Kontextlimit",
			"description": "Maximale Anzahl von Dateien, die in den Details des aktuellen Arbeitsverzeichnisses enthalten sein sollen. Höhere Werte bieten mehr Kontext, erhöhen aber den Token-Verbrauch."
		},
		"rooignore": {
			"label": ".rooignore-Dateien in Listen und Suchen anzeigen",
			"description": "Wenn aktiviert, werden Dateien, die mit Mustern in .rooignore übereinstimmen, in Listen mit einem Schlosssymbol angezeigt. Wenn deaktiviert, werden diese Dateien vollständig aus Dateilisten und Suchen ausgeblendet."
		},
		"maxConcurrentFileReads": {
			"label": "Concurrent file reads limit",
			"description": "Maximum number of files the 'read_file' tool can process concurrently. Higher values may speed up reading multiple small files but increase memory usage."
		},
		"maxReadFile": {
			"label": "Schwellenwert für automatische Dateilesekürzung",
			"description": "ModelHarbor liest diese Anzahl von Zeilen, wenn das Modell keine Start-/Endwerte angibt. Wenn diese Zahl kleiner als die Gesamtzahl der Zeilen ist, ModelHarbor erstellt einen Zeilennummernindex der Codedefinitionen. Spezialfälle: -1 weist ModelHarbor an, die gesamte Datei zu lesen (ohne Indexierung), und 0 weist an, keine Zeilen zu lesen und nur Zeilenindizes für minimalen Kontext bereitzustellen. Niedrigere Werte minimieren die anfängliche Kontextnutzung und ermöglichen präzise nachfolgende Zeilenbereich-Lesungen. Explizite Start-/End-Anfragen sind von dieser Einstellung nicht begrenzt.",
			"lines": "Zeilen",
			"always_full_read": "Immer die gesamte Datei lesen"
		},
		"condensingThreshold": {
			"label": "Schwellenwert für Kontextkomprimierung",
			"selectProfile": "Profil für Schwellenwert konfigurieren",
			"defaultProfile": "Globaler Standard (alle Profile)",
			"defaultDescription": "Wenn der Kontext diesen Prozentsatz erreicht, wird er automatisch für alle Profile komprimiert, es sei denn, sie haben benutzerdefinierte Einstellungen",
			"profileDescription": "Benutzerdefinierter Schwellenwert nur für dieses Profil (überschreibt globalen Standard)",
			"inheritDescription": "Dieses Profil erbt den globalen Standard-Schwellenwert ({{threshold}}%)",
			"usesGlobal": "(verwendet global {{threshold}}%)"
		}
	},
	"terminal": {
		"basic": {
			"label": "Terminal-Einstellungen: Grundlegend",
			"description": "Grundlegende Terminal-Einstellungen"
		},
		"advanced": {
			"label": "Terminal-Einstellungen: Erweitert",
			"description": "Die folgenden Optionen erfordern möglicherweise einen Terminal-Neustart, um die Einstellung zu übernehmen."
		},
		"outputLineLimit": {
			"label": "Terminal-Ausgabelimit",
			"description": "Maximale Anzahl von Zeilen, die in der Terminal-Ausgabe bei der Ausführung von Befehlen enthalten sein sollen. Bei Überschreitung werden Zeilen aus der Mitte entfernt, wodurch Token gespart werden. <0>Mehr erfahren</0>"
		},
		"shellIntegrationTimeout": {
			"label": "Terminal-Shell-Integrationszeit-Limit",
			"description": "Maximale Wartezeit für die Shell-Integration, bevor Befehle ausgeführt werden. Für Benutzer mit langen Shell-Startzeiten, musst du diesen Wert möglicherweise erhöhen, wenn du Fehler vom Typ \"Shell Integration Unavailable\" im Terminal siehst. <0>Mehr erfahren</0>"
		},
		"shellIntegrationDisabled": {
			"label": "Terminal-Shell-Integration deaktivieren",
			"description": "Aktiviere dies, wenn Terminalbefehle nicht korrekt funktionieren oder du Fehler wie 'Shell Integration Unavailable' siehst. Dies verwendet eine einfachere Methode zur Ausführung von Befehlen und umgeht einige erweiterte Terminalfunktionen. <0>Mehr erfahren</0>"
		},
		"commandDelay": {
			"label": "Terminal-Befehlsverzögerung",
			"description": "Verzögerung in Millisekunden, die nach der Befehlsausführung hinzugefügt wird. Die Standardeinstellung von 0 deaktiviert die Verzögerung vollständig. Dies kann dazu beitragen, dass die Befehlsausgabe in Terminals mit Timing-Problemen vollständig erfasst wird. In den meisten Terminals wird dies durch Setzen von `PROMPT_COMMAND='sleep N'` und Powershell fügt `start-sleep` am Ende jedes Befehls hinzu. Ursprünglich war dies eine Lösung für VSCode-Bug#237208 und ist möglicherweise nicht mehr erforderlich. <0>Mehr erfahren</0>"
		},
		"compressProgressBar": {
			"label": "Fortschrittsbalken-Ausgabe komprimieren",
			"description": "Wenn aktiviert, verarbeitet diese Option Terminal-Ausgaben mit Wagenrücklaufzeichen (\\r), um zu simulieren, wie ein echtes Terminal Inhalte anzeigen würde. Dies entfernt Zwischenzustände von Fortschrittsbalken und behält nur den Endzustand bei, wodurch Kontextraum für relevantere Informationen gespart wird. <0>Mehr erfahren</0>"
		},
		"powershellCounter": {
			"label": "PowerShell-Zähler-Workaround aktivieren",
			"description": "Wenn aktiviert, fügt einen Zähler zu PowerShell-Befehlen hinzu, um die korrekte Befehlsausführung sicherzustellen. Dies hilft bei PowerShell-Terminals, die Probleme mit der Ausgabeerfassung haben könnten. <0>Mehr erfahren</0>"
		},
		"zshClearEolMark": {
			"label": "ZSH-Zeilenende-Markierung löschen",
			"description": "Wenn aktiviert, wird die ZSH-Zeilenende-Markierung durch Setzen von PROMPT_EOL_MARK='' gelöscht. Dies verhindert Probleme bei der Interpretation der Befehlsausgabe, wenn diese mit Sonderzeichen wie '%' endet. <0>Mehr erfahren</0>"
		},
		"zshOhMy": {
			"label": "Oh My Zsh-Integration aktivieren",
			"description": "Wenn aktiviert, wird ITERM_SHELL_INTEGRATION_INSTALLED=Yes gesetzt, um die Shell-Integrationsfunktionen von Oh My Zsh zu aktivieren. Das Anwenden dieser Einstellung kann erfordern, dass die IDE neu gestartet wird. <0>Mehr erfahren</0>"
		},
		"zshP10k": {
			"label": "Powerlevel10k-Integration aktivieren",
			"description": "Wenn aktiviert, wird POWERLEVEL9K_TERM_SHELL_INTEGRATION=true gesetzt, um die Shell-Integrationsfunktionen von Powerlevel10k zu aktivieren. <0>Mehr erfahren</0>"
		},
		"zdotdir": {
			"label": "ZDOTDIR-Behandlung aktivieren",
			"description": "Erstellt bei Aktivierung ein temporäres Verzeichnis für ZDOTDIR, um die zsh-Shell-Integration korrekt zu handhaben. Dies stellt sicher, dass die VSCode-Shell-Integration mit zsh funktioniert und dabei deine zsh-Konfiguration erhalten bleibt. <0>Mehr erfahren</0>"
		},
		"inheritEnv": {
			"label": "Umgebungsvariablen übernehmen",
			"description": "Wenn aktiviert, übernimmt das Terminal Umgebungsvariablen vom übergeordneten VSCode-Prozess, wie z.B. in Benutzerprofilen definierte Shell-Integrationseinstellungen. Dies schaltet direkt die globale VSCode-Einstellung `terminal.integrated.inheritEnv` um. <0>Mehr erfahren</0>"
		}
	},
	"advanced": {
		"diff": {
			"label": "Bearbeitung durch Diffs aktivieren",
			"description": "Wenn aktiviert, kann ModelHarbor Dateien schneller bearbeiten und lehnt automatisch gekürzte vollständige Dateischreibvorgänge ab. Funktioniert am besten mit dem neuesten Claude 3.7 Sonnet-Modell.",
			"strategy": {
				"label": "Diff-Strategie",
				"options": {
					"standard": "Standard (Einzelner Block)",
					"multiBlock": "Experimentell: Multi-Block-Diff",
					"unified": "Experimentell: Vereinheitlichter Diff"
				},
				"descriptions": {
					"standard": "Die Standard-Diff-Strategie wendet Änderungen auf einen einzelnen Codeblock gleichzeitig an.",
					"unified": "Die vereinheitlichte Diff-Strategie verwendet mehrere Ansätze zum Anwenden von Diffs und wählt den besten Ansatz aus.",
					"multiBlock": "Die Multi-Block-Diff-Strategie ermöglicht die Aktualisierung mehrerer Codeblöcke in einer Datei in einer Anfrage."
				}
			},
			"matchPrecision": {
				"label": "Übereinstimmungsgenauigkeit",
				"description": "Dieser Schieberegler steuert, wie genau Codeabschnitte beim Anwenden von Diffs übereinstimmen müssen. Niedrigere Werte ermöglichen flexiblere Übereinstimmungen, erhöhen aber das Risiko falscher Ersetzungen. Verwende Werte unter 100% mit äußerster Vorsicht."
			}
		}
	},
	"experimental": {
		"DIFF_STRATEGY_UNIFIED": {
			"name": "Experimentelle einheitliche Diff-Strategie verwenden",
			"description": "Aktiviert die experimentelle einheitliche Diff-Strategie. Diese Strategie könnte die Anzahl der durch Modellfehler verursachten Wiederholungen reduzieren, kann aber unerwartetes Verhalten oder falsche Bearbeitungen verursachen. Nur aktivieren, wenn du die Risiken verstehst und bereit bist, alle Änderungen sorgfältig zu überprüfen."
		},
		"SEARCH_AND_REPLACE": {
			"name": "Experimentelles Such- und Ersetzungswerkzeug verwenden",
			"description": "Aktiviert das experimentelle Such- und Ersetzungswerkzeug, das ModelHarbor ermöglicht, mehrere Instanzen eines Suchbegriffs in einer Anfrage zu ersetzen."
		},
		"INSERT_BLOCK": {
			"name": "Experimentelles Inhalts-Einfüge-Werkzeug verwenden",
			"description": "Aktiviert das experimentelle Inhalts-Einfüge-Werkzeug, das ModelHarbor ermöglicht, Inhalte an bestimmten Zeilennummern einzufügen, ohne einen Diff erstellen zu müssen."
		},
		"POWER_STEERING": {
			"name": "Experimentellen \"Servolenkung\"-Modus verwenden",
			"description": "Wenn aktiviert, wird ModelHarbor das Modell häufiger an die Details seiner aktuellen Modusdefinition erinnern. Dies führt zu einer stärkeren Einhaltung von Rollen-Definitionen und benutzerdefinierten Anweisungen, verwendet aber mehr Tokens pro Nachricht."
		},
		"MULTI_SEARCH_AND_REPLACE": {
			"name": "Experimentelles Multi-Block-Diff-Werkzeug verwenden",
			"description": "Wenn aktiviert, verwendet ModelHarbor das Multi-Block-Diff-Werkzeug. Dies versucht, mehrere Codeblöcke in der Datei in einer Anfrage zu aktualisieren."
		},
		"CONCURRENT_FILE_READS": {
			"name": "Gleichzeitiges Lesen von Dateien aktivieren",
			"description": "Wenn aktiviert, kann ModelHarbor mehrere Dateien in einer einzigen Anfrage lesen. Wenn deaktiviert, muss ModelHarbor Dateien nacheinander lesen. Das Deaktivieren kann helfen, wenn du mit weniger leistungsfähigen Modellen arbeitest oder mehr Kontrolle über den Dateizugriff haben möchtest."
		},
		"MARKETPLACE": {
			"name": "Marketplace aktivieren",
			"description": "Wenn aktiviert, kannst du MCP und benutzerdefinierte Modi aus dem Marketplace installieren und verwalten."
		},
		"MULTI_FILE_APPLY_DIFF": {
			"name": "Gleichzeitige Dateibearbeitungen aktivieren",
			"description": "Wenn aktiviert, kann ModelHarbor mehrere Dateien in einer einzigen Anfrage bearbeiten. Wenn deaktiviert, muss ModelHarbor Dateien einzeln bearbeiten. Das Deaktivieren kann helfen, wenn du mit weniger fähigen Modellen arbeitest oder mehr Kontrolle über Dateiänderungen haben möchtest."
		}
	},
	"promptCaching": {
		"label": "Prompt-Caching deaktivieren",
		"description": "Wenn aktiviert, wird ModelHarbor für dieses Modell kein Prompt-Caching verwenden."
	},
	"temperature": {
		"useCustom": "Benutzerdefinierte Temperatur verwenden",
		"description": "Steuert die Zufälligkeit in den Antworten des Modells.",
		"rangeDescription": "Höhere Werte machen die Ausgabe zufälliger, niedrigere Werte machen sie deterministischer."
	},
	"modelInfo": {
		"supportsImages": "Unterstützt Bilder",
		"noImages": "Unterstützt keine Bilder",
		"supportsComputerUse": "Unterstützt Computer-Nutzung",
		"noComputerUse": "Unterstützt keine Computer-Nutzung",
		"supportsPromptCache": "Unterstützt Prompt-Caching",
		"noPromptCache": "Unterstützt kein Prompt-Caching",
		"maxOutput": "Maximale Ausgabe",
		"inputPrice": "Eingabepreis",
		"outputPrice": "Ausgabepreis",
		"cacheReadsPrice": "Cache-Lesepreis",
		"cacheWritesPrice": "Cache-Schreibpreis",
		"enableStreaming": "Streaming aktivieren",
		"enableR1Format": "R1-Modellparameter aktivieren",
		"enableR1FormatTips": "Muss aktiviert werden, wenn R1-Modelle wie QWQ verwendet werden, um 400-Fehler zu vermeiden",
		"useAzure": "Azure verwenden",
		"azureApiVersion": "Azure API-Version festlegen",
		"gemini": {
			"freeRequests": "* Kostenlos bis zu {{count}} Anfragen pro Minute. Danach hängt die Abrechnung von der Prompt-Größe ab.",
			"pricingDetails": "Weitere Informationen finden Sie in den Preisdetails.",
			"billingEstimate": "* Die Abrechnung ist eine Schätzung - die genauen Kosten hängen von der Prompt-Größe ab."
		}
	},
	"modelPicker": {
		"automaticFetch": "Die Erweiterung ruft automatisch die neueste Liste der verfügbaren Modelle von <serviceLink>{{serviceName}}</serviceLink> ab. Wenn du dir nicht sicher bist, welches Modell du wählen sollst, funktioniert ModelHarbor Agent am besten mit <defaultModelLink>{{defaultModelId}}</defaultModelLink>. Du kannst auch nach \"free\" suchen, um derzeit verfügbare kostenlose Optionen zu finden.",
		"label": "Modell",
		"searchPlaceholder": "Suchen",
		"noMatchFound": "Keine Übereinstimmung gefunden",
		"useCustomModel": "Benutzerdefiniert verwenden: {{modelId}}"
	},
	"footer": {
		"feedback": "Wenn du Fragen oder Feedback hast, kannst du gerne ein Issue auf <githubLink>github.com/ModelHarbor/ModelHarbor-Agent</githubLink> öffnen oder <redditLink>reddit.com/r/ModelHarbor</redditLink> oder <discordLink>discord.gg/modelharbor</discordLink> beitreten",
		"telemetry": {
			"label": "Anonyme Fehler- und Nutzungsberichte zulassen",
			"description": "Helfen Sie, ModelHarbor Agent zu verbessern, indem Sie anonyme Nutzungsdaten und Fehlerberichte senden. Es werden niemals Code, Prompts oder persönliche Informationen gesendet. Weitere Details finden Sie in unserer Datenschutzrichtlinie."
		},
		"settings": {
			"import": "Importieren",
			"export": "Exportieren",
			"reset": "Zurücksetzen"
		}
	},
	"thinkingBudget": {
		"maxTokens": "Maximale Tokens",
		"maxThinkingTokens": "Maximale Thinking-Tokens"
	},
	"validation": {
		"apiKey": "Du musst einen gültigen API-Schlüssel angeben.",
		"awsRegion": "Du musst eine Region für Amazon Bedrock auswählen.",
		"googleCloud": "Du musst eine gültige Google Cloud Projekt-ID und Region angeben.",
		"modelId": "Du musst eine gültige Modell-ID angeben.",
		"modelSelector": "Du musst einen gültigen Modell-Selektor angeben.",
		"openAi": "Du musst eine gültige Basis-URL, API-Schlüssel und Modell-ID angeben.",
		"arn": {
			"invalidFormat": "Ungültiges ARN-Format. Bitte überprüfen Sie die Formatanforderungen.",
			"regionMismatch": "Warnung: Die Region in deiner ARN ({{arnRegion}}) stimmt nicht mit deiner ausgewählten Region ({{region}}) überein. Dies kann zu Zugriffsproblemen führen. Der Provider wird die Region aus der ARN verwenden."
		},
		"modelAvailability": "Die von dir angegebene Modell-ID ({{modelId}}) ist nicht verfügbar. Bitte wähle ein anderes Modell.",
		"providerNotAllowed": "Anbieter '{{provider}}' ist von deiner Organisation nicht erlaubt",
		"modelNotAllowed": "Modell '{{model}}' ist für Anbieter '{{provider}}' von deiner Organisation nicht erlaubt",
		"profileInvalid": "Dieses Profil enthält einen Anbieter oder ein Modell, das von deiner Organisation nicht erlaubt ist"
	},
	"placeholders": {
		"apiKey": "API-Schlüssel eingeben...",
		"profileName": "Profilnamen eingeben",
		"accessKey": "Zugriffsschlüssel eingeben...",
		"secretKey": "Geheimschlüssel eingeben...",
		"sessionToken": "Sitzungstoken eingeben...",
		"credentialsJson": "Anmeldedaten-JSON eingeben...",
		"keyFilePath": "Schlüsseldateipfad eingeben...",
		"projectId": "Projekt-ID eingeben...",
		"customArn": "ARN eingeben (z.B. arn:aws:bedrock:us-east-1:123456789012:foundation-model/my-model)",
		"baseUrl": "Basis-URL eingeben...",
		"modelId": {
			"lmStudio": "z.B. meta-llama-3.1-8b-instruct",
			"lmStudioDraft": "z.B. lmstudio-community/llama-3.2-1b-instruct",
			"ollama": "z.B. llama3.1"
		},
		"numbers": {
			"maxTokens": "z.B. 4096",
			"contextWindow": "z.B. 128000",
			"inputPrice": "z.B. 0.0001",
			"outputPrice": "z.B. 0.0002",
			"cacheWritePrice": "z.B. 0.00005"
		}
	},
	"defaults": {
		"ollamaUrl": "Standard: http://localhost:11434",
		"lmStudioUrl": "Standard: http://localhost:1234",
		"geminiUrl": "Standard: https://generativelanguage.googleapis.com"
	},
	"labels": {
		"customArn": "Benutzerdefinierte ARN",
		"useCustomArn": "Benutzerdefinierte ARN verwenden..."
	},
	"includeMaxOutputTokens": "Maximale Ausgabe-Tokens einbeziehen",
	"includeMaxOutputTokensDescription": "Sende den Parameter für maximale Ausgabe-Tokens in API-Anfragen. Einige Anbieter unterstützen dies möglicherweise nicht."
}
